
	Intel Open Visual Inference and Neural network Optimization (OpenVINO)

1. Overview
===========

Intel Open Visual Inference and Neural network Optimization (OpenVINO)
is use to helps developers and data scientists speed up computer vision
workloads, streamline deep learning inference and deployments, and enable
easy, heterogeneous execution across Intel platforms.

2. Build Configuration
======================

When OpenVNIO feature is included in your build, the following components
will be added to your final image:

    dldt-inference-engine
    dldt-model-optimizer
    open-model-zoo

To enable this feature, please add the following configuration parameter:
    --template=feature/intel-openvino

Some demos in OpenVINO need graphic support, it can work well with the
following types of images:

    wrlinux-image-std-sato
    wrlinux-image-std + xfce

3. OpenVINO examples applications
=================================
You can find demos in /usr/bin/, some useful tools are installed
in /usr/share/openvino

Before run demos, the .xml and .bin file need to be download to your host
with the tool:

/usr/share/openvino/open-model-zoo/tools/downloader/downloader.py

Take human_pose_estimation_demo for example:

   $ /usr/share/openvino/open-model-zoo/tools/downloader/downloader.py --print_all |grep human-pose-estimation
   human-pose-estimation-0001
   human-pose-estimation-3d-0001
   single-human-pose-estimation-0001

   $ /usr/share/openvino/open-model-zoo/tools/downloader/downloader.py --name human-pose-estimation-0001

the xml files will be download into ./intel directory

root@intel-x86-64:~# tree intel/
intel/
`-- human-pose-estimation-0001
    |-- FP16
    |   |-- human-pose-estimation-0001.bin
    |   `-- human-pose-estimation-0001.xml
    |-- FP32
    |   |-- human-pose-estimation-0001.bin
    |   `-- human-pose-estimation-0001.xml
    `-- FP32-INT8
        |-- human-pose-estimation-0001.bin
        `-- human-pose-estimation-0001.xml

if an usb camera is connect, run with

   $ /usr/bin/human_pose_estimation_demo -i cam -m intel/human-pose-estimation-0001/FP32/human-pose-estimation-0001.xml -d CPU

run with -h will show you the available target devices can be specified by -d

   $ /usr/bin/human_pose_estimation_demo -h
   ...
   Available target devices:  CPU

4. model-optimizer
==================

OpenVNIO model optimizer support convert Pre-trained models to IR files which can
be used by Inference Engine directly, but it does not support training modes.
for WRLinux, it supports convert Tensorflow Pre-trained models to IR files.
Build with template feature/tensorflow to enable tensorflow in WRLinux.

A sample to convert TF models to IR files:

   $ /usr/share/openvino/model-optimizer/mo_tf.py --input_model /root/tf_model.pb --freeze_placeholder_with_value "phase_train->False"
   [ SUCCESS ] Generated IR version 10 model.
   [ SUCCESS ] XML file: /root/./tf_model.xml
   [ SUCCESS ] BIN file: /root/./tf_model.bin
   [ SUCCESS ] Total execution time: 62.22 seconds.
   [ SUCCESS ] Memory consumed: 813 MB.


5. Additional documentation
===========================

More documents and usage of the demos please refer to:
https://docs.openvinotoolkit.org/latest/_docs_resources_introduction.html

6. Known Issues
================

1) when download xml files may meet the following error:
requests.exceptions.SSLError: HTTPSConnectionPool(host='download.01.org', port=443): Max retries exceeded with url: /opencv/2020/openvinotoolkit/2020.1/open_model_zoo/models_bin/1/human-pose-estimation-0001/FP32/human-pose-estimation-0001.xml (Caused by SSLError(SSLError("bad handshake: Error([('SSL routines', 'ssl3_get_record',

This is due to a slow network rate, or we may need a network proxy to download it.

2) converter.py is not supported since the dependency tools torch, torchvision and scipy was not available in yocto

3) run demos with .mp4 file may failed since gstreamer1.0-libav was not installed,
   add the following line to conf/local.conf to install it:

   LICENSE_FLAGS_WHITELIST_append = " commercial"
   IMAGE_INSTALL_append = " gstreamer1.0-libav"


#@TYPE: Wrtemplate
#@NAME: intel-openvino
#@DESCRIPTION: Intel Open Visual Inference and Neural network Optimization (OpenVINO)
