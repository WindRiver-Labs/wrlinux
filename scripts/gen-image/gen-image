#!/usr/bin/env python3
#
# Copyright (C) 2020 Wind River Systems, Inc.
#
# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License version 2 as
# published by the Free Software Foundation.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
# See the GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program; if not, write to the Free Software
# Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA

import os
import sys
import subprocess
import argparse
import logging
import shutil
import glob
import time
import hashlib
import git
import socket

logger = logging.getLogger('gen-image')

def get_project():
    runqemu_dir = os.path.realpath(shutil.which("runqemu"))
    return os.path.realpath("%s/../../../../" % runqemu_dir)

def run_cmd(cmd, logger):
    logger.debug('Running %s' % cmd)

    try:
        output = subprocess.check_output(cmd, shell=True, stderr=subprocess.STDOUT)
        output = output.decode('utf-8')
        logger.debug('output: %s' % output)
    except subprocess.CalledProcessError as e:
        raise Exception("%s\n%s" % (str(e), e.output.decode('utf-8')))

    return output

def run_bitbake_cmd(target, logger):
    cmd = 'bitbake %s' % target
    logger.info('Running %s' % cmd)
    output = run_cmd(cmd, logger)
    return output

def set_logger(logger):
    logger.setLevel(logging.DEBUG)

    class ColorFormatter(logging.Formatter):
        FORMAT = ("$BOLD%(name)-s$RESET - %(levelname)s: %(message)s")

        BLACK, RED, GREEN, YELLOW, BLUE, MAGENTA, CYAN, WHITE = list(range(8))

        RESET_SEQ = "\033[0m"
        COLOR_SEQ = "\033[1;%dm"
        BOLD_SEQ = "\033[1m"

        COLORS = {
            'WARNING': YELLOW,
            'INFO': GREEN,
            'DEBUG': BLUE,
            'ERROR': RED
        }

        def formatter_msg(self, msg, use_color = True):
            if use_color:
                msg = msg.replace("$RESET", self.RESET_SEQ).replace("$BOLD", self.BOLD_SEQ)
            else:
                msg = msg.replace("$RESET", "").replace("$BOLD", "")
            return msg

        def __init__(self, use_color=True):
            msg = self.formatter_msg(self.FORMAT, use_color)
            logging.Formatter.__init__(self, msg)
            self.use_color = use_color

        def format(self, record):
            levelname = record.levelname
            if self.use_color and levelname in self.COLORS:
                fore_color = 30 + self.COLORS[levelname]
                levelname_color = self.COLOR_SEQ % fore_color + levelname + self.RESET_SEQ
                record.levelname = levelname_color
            return logging.Formatter.format(self, record)

    # create console handler and set level to debug
    ch = logging.StreamHandler()
    ch.setLevel(logging.DEBUG)
    ch.setFormatter(ColorFormatter())
    logger.addHandler(ch)

def get_today():
    return time.strftime("%Y%m%d%H%M%S")

set_logger(logger)

class GenImage(object):
    """
    * Generate the following images in order:
        - Linux SDK
        - target images
        - container image
    * world build for packages feeds
    * Save/Re-use PR database prserv.sqlite3
    * Gen sources for IP review
    """

    def __init__(self):
        self.supported_machines = [
            'intel-x86-64',
            'bcm-2xxx-rpi4',
        ]

        self.data_dir = os.path.join(os.path.dirname(sys.argv[0]), 'data')
        self.bin_image_conf = os.path.join(os.path.dirname(sys.argv[0]), 'data', 'wrlinux-bin-image.conf')
        self.container_conf = os.path.join(os.path.dirname(sys.argv[0]), 'data', 'wrlinux-container.conf')

        parser = argparse.ArgumentParser(
            description="Gen images for specified machine",
            epilog="Use %(prog)s --help to get help")
        parser.add_argument('-m', '--machine',
            default='',
            help='Specify machine')
        parser.add_argument('-r', '--ip-review',
            default=False,
            help='Only generate sources for IP review', action="store_true")
        parser.add_argument('-g', '--gen-recipes',
            default=False,
            help='Generate recipes list used by the image', action="store_true")
        parser.add_argument('-b', '--pr-database',
            default=os.path.join(self.data_dir, 'prserv.sqlite3'),
            help='Specify PR database to use, no database will be used if specified no', action="store")
        parser.add_argument('-o', '--outdir',
            default=None,
            help='Specify the output dir', action="store")
        parser.add_argument('-u', '--upload-url',
            default=None,
            help='Specify the url to upload the files, which uses rsync to upload the files', action="store")
        parser.add_argument('-p', '--product', choices=['lincd'], required=False,
            default='lincd',
            help='Specify the product', action="store")
        parser.add_argument("-d", "--debug",
            help = "Enable debug output",
            action="store_const", const=logging.DEBUG, dest="loglevel", default=logging.INFO)
        parser.add_argument("-q", "--quiet",
            help = "Hide all output except error messages",
            action="store_const", const=logging.ERROR, dest="loglevel")

        self.args = parser.parse_args()

        logger.setLevel(self.args.loglevel)

        bitbake_path = shutil.which('bitbake')
        self.builddir = os.getenv('BUILDDIR')
        if not (bitbake_path and self.builddir):
            raise Exception('bitbake command is not found, this tools should be run after source oe-init-build-env')

        self.today = get_today()

        self.project = get_project()

        self.machine = self.args.machine

        self.image_minimal = 'wrlinux-image-minimal'
        self.image_full = 'wrlinux-image-full'
        self.image = os.getenv('IMAGE', '')
        if self.image:
            logger.info('Got IMAGE %s from environment vars' % self.image)
            self.images = [self.image]
        else:
            # Default image
            self.image = self.image_full
            self.images = [self.image_minimal, self.image_full]

        self.doc_dir = os.path.join(os.path.dirname(sys.argv[0]), 'doc')

        self.local_layer = os.path.join(self.project, 'layers/local')

        self.local_conf = os.path.join(self.builddir, 'conf/local.conf')

        if self.args.product == 'lincd':
            self.handoff_name = 'WRLinux-CD-Images'
        else:
            self.handoff_name = self.args.product

        if self.args.outdir:
            self.outdir = self.args.outdir
        else:
            self.outdir = os.path.join(self.builddir, 'outdir')

        self.handoff_dir = os.path.join(self.outdir, self.handoff_name)

        self.cache_dir = os.path.join(self.builddir, 'cache')
        if not os.path.exists(self.cache_dir):
            os.makedirs(self.cache_dir)

        self.pr_db = os.path.join(self.cache_dir, 'prserv.sqlite3')
        self.pr_log = os.path.join(self.builddir, 'cache/prserv.log')
        self.pr_dir = os.path.join(self.handoff_dir, 'prserv')

    def prepare(self):

        bitbake_e = ''
        if not self.machine:
            logger.info('Figuring out machine ...')
            bitbake_e = self.do_build('-e')
            for line in bitbake_e.split('\n'):
                if line.startswith('PKGDATA_DIR='):
                    self.machine = line.split('=')[1].replace('"', '')
                    self.machine = os.path.basename(self.machine)
                    break

        logger.info('Generating images for %s' % self.machine)
        self.repos_dir = os.path.join(self.handoff_dir, self.machine, 'repos')

        if self.args.pr_database and os.path.exists(self.args.pr_database):
            if not self.args.pr_database.endswith('.sqlite3'):
                raise Exception('Invalid PR databse file: %s' % self.args.pr_database)
            logger.info('Using %s as pr database' % self.args.pr_database)
            shutil.copy(self.args.pr_database, self.pr_db)
        elif self.args.pr_database in ('no', 'No', 'NO') and os.path.exists(self.pr_db):
            logger.info('Removing %s' % self.pr_db)
            os.remove(self.pr_db)

        if self.machine:
            self.mv_to_old(self.machine)

        if not os.path.exists(self.handoff_dir):
            os.makedirs(self.handoff_dir)

        with open(self.local_conf, 'a+') as f:
            # Only need write MACHIINE when it is not specified
            if not bitbake_e:
                f.write('\nMACHINE = "%s"\n' % self.machine)
            line = 'require %s\n' % self.bin_image_conf
            if self.image in (self.image_minimal, self.image_full):
                f.seek(0)
                if not line in f.readlines():
                    logger.info('Writting %s to conf/local.conf' % line)
                    f.write(line)

        self.feed_archs = []
        all_archs = []
        if not bitbake_e:
            bitbake_e = self.do_build('-e')

        feed_uris_defined = False
        for line in bitbake_e.split('\n'):
            if line.startswith('PACKAGE_FEED_URIS='):
                feed_uris_defined = True
            if line.startswith('PACKAGE_FEED_ARCHS='):
                self.feed_archs = line.split('=')[1].replace('"', '').split()
            if line.startswith('ALL_MULTILIB_PACKAGE_ARCHS='):
                all_archs = line.split('=')[1].replace('"', '').split()
            if line.startswith('TMPDIR='):
                self.tmpdir = line.split('=')[1].replace('"', '')

        if not self.feed_archs:
            if not all_archs:
                raise Exception("Failed to figure out feed_archs")
            logger.info("PACKAGE_FEED_ARCHS is not defined, set it automatically")
            for arch in all_archs:
                self.feed_archs.append(arch.replace("-", "_"))

        if not self.tmpdir:
            raise Exception("Failed to figure tmpdir!")

        if not feed_uris_defined:
            port = '9310'
            hostname = socket.gethostname()
            uri = 'http://%s:%s/outdir' % (hostname, port)
            logger.warning('PACKAGE_FEED_URIS is not defined, setting it to %s' % uri)

            with open(self.local_conf, 'a+') as f:
                line = 'PACKAGE_FEED_URIS = "%s"\n' % uri
                f.seek(0)
                if not line in f.readlines():
                    f.write(line)

    def mv_to_old(self, src_name):
        src = os.path.join(self.handoff_dir, src_name)
        old_dir = os.path.join(self.outdir, 'old')
        dst = os.path.join(old_dir, '%s.%s' % (os.path.basename(src), self.today))
        if not os.path.exists(old_dir):
            os.makedirs(old_dir)
        if os.path.exists(src):
            shutil.move(src, dst)

    def do_build(self, target=None, conf=None):
        if conf:
            with open(self.local_conf, 'a') as f:
                f.write(conf)

        if not target:
            target = self.image
        output = run_bitbake_cmd(target, logger)
        return output

    def do_deploy(self, subdir, files):
        logger.info('Deploying %s' % subdir)

        def do_copy(src, dst_dir):
            if not os.path.exists(dst_dir):
                os.makedirs(dst_dir)
            shutil.copy(src, dst_dir)

        # The image file copy once, ovmf and document copy twice into the
        # following dirs:
        # - container-minimal
        # - container-full
        # - target-minimal
        # - target-full
        dst_dir = os.path.join(self.handoff_dir, subdir)
        dst_dir_minimal = '%s-minimal-%s' % (dst_dir, self.machine)
        dst_dir_full = '%s-full-%s' % (dst_dir, self.machine)
        dst_dir_sdk = '%s-%s' % (dst_dir, self.machine)
        copy_twice = False
        if self.image_minimal in ' '.join(files):
            copy_twice = True
        for f in files:
            if subdir.endswith('/sdk') or subdir.endswith('/lat'):
                do_copy(f, dst_dir_sdk)
            elif self.image_minimal in f:
                do_copy(f, dst_dir_minimal)
            elif self.image_full in f:
                do_copy(f, dst_dir_full)
            elif copy_twice:
                do_copy(f, dst_dir_minimal)
                do_copy(f, dst_dir_full)
            else:
                do_copy(f, dst_dir)

    def gen_sdk(self):
        logger.info('Generating sdk...')

        self.do_build('%s -cpopulate_sdk' % self.image)
        deploy_files = []

        deploy_dir = os.path.join(self.tmpdir, 'deploy/sdk')
        suffixes = ['sdk.sh', 'sdk.host.manifest', 'sdk.target.manifest']
        for f in suffixes:
            wildcard = "%s/*-%s-%s-%s" % (deploy_dir, self.machine.replace('-', '_'), self.image, f)
            files = glob.glob(wildcard)
            if len(files) != 1:
                raise Exception("Should be only one %s file but found %s: \n%s" % (f, len(files), '\n'.join(files)))
            deploy_files.append(files[0])

        deploy_files.append(os.path.join(self.doc_dir, 'sdk.README.md'))

        self.do_deploy('%s/sdk' % self.machine, deploy_files)

    def gen_lat(self):
        logger.info('Generating base reference container for Linux Assembly Tool...')
        if not self.machine in ('intel-x86-64', 'bcm-2xxx-rpi4'):
            logger.info('Skipping Linux Assembly Tool: Not supported')
            return

        self.do_build('container-base')

        logger.info('Generating app sdk for Linux Assembly Tool...')
        self.do_build('container-base -cpopulate_sdk')

        deploy_files = self.get_deploy_files(type='tar.bz2', ovmf=False, uboot=False, images=['container-base'])
        deploy_dir = os.path.join(self.tmpdir, 'deploy/sdk')
        suffixes = ['sdk.sh', 'sdk.host.manifest', 'sdk.target.manifest']
        for f in suffixes:
            wildcard = "%s/*-%s-container-base-%s" % (deploy_dir, self.machine.replace('-', '_'), f)
            files = glob.glob(wildcard)
            if len(files) != 1:
                raise Exception("Should be only one %s file but found %s: \n%s" % (f, len(files), '\n'.join(files)))
            deploy_files.append(files[0])

        deploy_files.append(os.path.join(self.doc_dir, 'appsdk.README.md'))
        self.do_deploy('%s/lat' % self.machine, deploy_files)

    def get_deploy_files(self, type='', ovmf=True, uboot=True, images=[]):
        deploy_dir = os.path.join(self.tmpdir, 'deploy/images/%s' % self.machine)
        deploy_files = []
        if not images:
            images = self.images
        for image in images:
            prefix = '%s/%s-%s' % (deploy_dir, image, self.machine)
            if type:
                deploy_files.append('%s.%s' % (prefix, type))
            deploy_files.append('%s.manifest' % prefix)
        if ovmf:
            deploy_files.append('%s/ovmf.qcow2' % deploy_dir)
        if uboot:
            if self.machine == "bcm-2xxx-rpi4":
                qemu_u_boot = os.path.join(deploy_dir, 'qemu-u-boot-bcm-2xxx-rpi4.bin')
                deploy_files.append(qemu_u_boot)
        for f in deploy_files:
            logger.debug('Deploy file: %s' % f)
            if not os.path.exists(f):
                raise Exception('Failed to find %s' % f)

        return deploy_files

    def gen_ostree(self):
        logger.info('Generating target image...')

        deploy_files = set()
        is_x86 = 'intel' in self.machine or 'x86-64' in self.machine

        # Remove ostreerepo_dir to avoid mixing minimal and full, otherwise the
        # minimal's size would be large in the second run.
        ostreerepo_dir = os.path.join(self.tmpdir, 'deploy/images/%s/ostree_repo' % self.machine)
        if os.path.exists(ostreerepo_dir):
            ostreerepo_dir_saved = '%s.%s.%s' % (ostreerepo_dir, self.machine, self.today)
            shutil.move(ostreerepo_dir, ostreerepo_dir_saved)
        else:
            logger.debug("%s doesn't exist" % ostreerepo_dir)

        self.do_build('%s -cclean' % ' '.join(self.images))
        for image in self.images:
            self.do_build(target=image)

            # Regenerate wic image to support disk resize
            if os.path.exists(ostreerepo_dir):
                cmd = "%s/layers/wr-ostree/scripts/bootfs.sh -L -b %s -s 512 -a 'instdate=BUILD_DATE instw=60'" % (self.project, image)
                run_cmd(cmd, logger)

            new_image = ""
            deploy_files |= set(self.get_deploy_files(ovmf=is_x86, uboot=not is_x86, images=[image]))
            basename = '%s-%s' % (image, self.machine)
            ustart_images = ['ustart.img.bmap']
            if self.machine == 'nxp-s32g2xx':
                ustart_images += ['ustart-evb.img.gz', 'ustart-rdb2.img.gz']
            else:
                ustart_images.append('ustart.img.gz')

            for f in ustart_images:
                newf = os.path.join(self.builddir, '%s.%s' % (basename, f))
                os.rename(f, newf)
                deploy_files.add(newf)

        readme = os.path.join(self.doc_dir, 'target_%s.README.md' %  self.machine)
        if os.path.exists(readme):
            deploy_files.add(os.path.join(self.doc_dir, 'target_%s.README.md' %  self.machine))
        else:
            logger.warning('%s: No README' % self.machine)

        self.do_deploy('%s/target' % self.machine, deploy_files)

        logger.info('Deploying %s/repos/ostree_repo...' % self.machine)
        dst_dir = os.path.join(self.repos_dir, 'ostree_repo')
        if os.path.exists(ostreerepo_dir):
            shutil.copytree(ostreerepo_dir, dst_dir)

    def gen_container(self):
        logger.info('Generating container image...')

        for image in self.images:
            self.do_build(target='%s -r %s' % (image, self.container_conf))

        deploy_files = self.get_deploy_files(type='tar.bz2', ovmf=False, uboot=False)

        deploy_files.append(os.path.join(self.doc_dir, 'container.README.md'))
        self.do_deploy('%s/container' % self.machine, deploy_files)

    def gen_feeds(self):
        logger.info('Generating packages feeds...')
        # The docker won't be built in a world build since it is started by virtual.
        self.do_build('world docker %s' % ' '.join(self.images))

        # Remove unneeded archs
        rpm_dir = os.path.join(self.tmpdir, 'deploy/rpm')
        existed_archs = os.listdir(rpm_dir)
        for e in existed_archs:
            if e.startswith('.pkgdata.tar.bz2'):
                continue
            if not e in self.feed_archs:
                e_path = os.path.join(rpm_dir, e)
                logger.info('Removing unneeded data: %s' % e_path)
                shutil.rmtree(e_path)

        self.do_build('package-index')

        if not os.path.exists(self.repos_dir):
            os.makedirs(self.repos_dir)

        logger.info('Deploying %s/repos/rpm' % self.machine)
        dst_dir = os.path.join(self.repos_dir, 'rpm')
        shutil.copytree(rpm_dir, dst_dir)

    def post(self):
        with open(self.local_conf, 'a') as f:
            f.write('#### Done by gen-image\n')

        # Save local.conf
        local_conf_machine = '%s.%s' % (self.local_conf, self.machine)
        shutil.copy(self.local_conf, local_conf_machine)
        logger.info('The local.conf is saved to %s' % local_conf_machine)

        # Save prserver
        self.mv_to_old('prserv')
        os.makedirs(self.pr_dir)
        shutil.copy(self.pr_db, self.pr_dir)
        shutil.copy(self.pr_log, self.pr_dir)

        # Generate sha256 for the following files
        # - container/*.tar.bz2
        # - target/*.img.gz ovmf.qcow2
        # - sdk/*.sh
        tgts = ("container-*/*.tar.bz2", "target-*/*.img.gz", "target-*/ovmf.qcow2", "sdk/*.sh")
        sha256files = []
        file_prefix = os.path.join(self.handoff_dir, self.machine)
        for tgt in tgts:
            fmt = os.path.join(file_prefix, tgt)
            for f in glob.glob(fmt):
                sha256files.append(f)
        outlist = []
        if sha256files:
                for sha256file in sha256files:
                    basename = os.path.basename(sha256file)
                    logger.info('Generating checksum for %s' % basename)
                    with open(sha256file, 'rb') as inf:
                        data = inf.read()
                    m = hashlib.sha256()
                    m.update(data)

                    dirname = os.path.dirname(sha256file)
                    outfile = os.path.join(dirname, 'sha256sum.txt')
                    with open(outfile, 'a+') as f:
                        f.write('%s *%s\n' % (m.hexdigest(), basename))
        else:
            logger.warning("The checksum is not generated since no files are found!")

        # Create tarballs for target minimal/full and sdk directories
        if os.path.exists(file_prefix):
            for d in os.listdir(file_prefix):
                if ('-minimal-' in d or '-full-' in d or 'sdk-' in d or 'lat-' in d) and not d.startswith('container-'):
                    cmd = 'tar --numeric-owner -cjvf %s.tar.bz2 %s' % (d, d)
                    logger.debug('Running %s' % cmd)
                    subprocess.check_output(cmd, shell=True, cwd=file_prefix)
        logger.info('Deploy files: %s' % os.path.join(self.handoff_dir, self.machine))

    def ip_review(self):
        ip_conf = """
# For IP review
WRTEMPLATE += "feature/archiver"
COPYLEFT_LICENSE_INCLUDE = "*"
COPYLEFT_LICENSE_EXCLUDE = ""
"""
        logger.info('Generating sources for IP review')
        # The docker won't be built in a world build since it is started with "virtual/".
        # The "bitbake world docker --runall=deploy_archives" doesn't work, so build world.
        self.do_build('world docker %s %s --runall=deploy_archives' % ' '.join(self.images), conf=ip_conf)

        # And sdk
        # The "bitbake wrlinux-image-full --runall=deploy_archives -cpopulate_sdk"
        # doesn't work, so we figure out the list and build them one by one
        self.do_build('%s -cpopulate_sdk -g' % self.image)
        recipes = []
        with open('pn-buildlist') as f:
            for line in f.readlines():
                line = line.strip()
                # Only native sdk recipes are needed since others have already been built
                if line.startswith('nativesdk-') and line != 'nativesdk-libgcc-initial':
                    recipes.append(line)

        self.do_build('%s -cdeploy_archives' % ' '.join(recipes))

        src_dir = os.path.join(self.tmpdir, 'deploy/sources')
        logger.info('Deploying sources-%s' % self.machine)
        dst_dir = os.path.join(self.handoff_dir, 'sources-%s' % self.machine)
        self.mv_to_old('sources-%s' % self.machine)
        cmd = 'rsync -a --exclude "*-native-*" %s/*/* %s' % (src_dir, dst_dir)
        logger.info('Running %s' % cmd)
        subprocess.check_call(cmd, shell=True)

    def do_upload(self):
        logger.info('Preparing upload files...')
        self.local_upload_dir = os.path.join(self.outdir, 'upload')
        date = time.strftime("%Y-%m-%d")
        self.local_upload_dir_date = os.path.join(self.local_upload_dir, date)
        if os.path.exists(self.local_upload_dir):
            self.mv_to_old('../upload')

        os.makedirs(self.local_upload_dir)

        local_handoff_dir = os.path.join(self.local_upload_dir_date, self.handoff_name)
        if not os.path.exists(local_handoff_dir):
            os.makedirs(local_handoff_dir)

        dst_dir_container = os.path.join(self.local_upload_dir_date, 'containers')
        local_sources = os.path.join(local_handoff_dir, 'sources')
        for m in os.listdir(self.handoff_dir):
            if m == 'prserv':
                continue
            file_prefix_src = os.path.join(self.handoff_dir, 'sources-%s' % m)
            if os.path.exists(file_prefix_src):
                cmd = 'rsync -a %s/* %s' % (file_prefix_src, local_sources)
                logger.info('Running %s' % cmd)
                subprocess.check_call(cmd, shell=True)

            file_prefix = os.path.join(self.handoff_dir, m)
            if os.path.exists(file_prefix):
                dst_dir_tgt = os.path.join(local_handoff_dir, m)
                if not os.path.exists(dst_dir_tgt):
                    os.makedirs(dst_dir_tgt)
                for d in os.listdir(file_prefix):
                    d_path = os.path.join(file_prefix, d)
                    if d.startswith('lat-'):
                        continue
                    elif d.startswith('container-'):
                        shutil.copytree(d_path, os.path.join(dst_dir_container, d))
                    elif d.endswith('.tar.bz2'):
                        shutil.copy(d_path, dst_dir_tgt)
                    elif d == 'repos':
                        shutil.copytree(d_path, os.path.join(dst_dir_tgt, d))

                # Save config info
                logfile = 'tmp-%s-glibc/log/cooker/%s/console-latest.log' % (m, m)
                config_out = os.path.join(self.local_upload_dir_date, 'config_%s' % m)
                newlines = []
                with open(logfile, 'r') as f:
                    for line in f.readlines():
                        if line.startswith('Build Configuration:'):
                            newlines.append(line)
                            continue
                        if line.startswith('--------------------'):
                            break
                        if newlines:
                            newlines.append(line)
                if newlines:
                    with open(config_out, 'w') as f:
                        f.write(''.join(newlines))
                else:
                    logger.warning('Failed to find config info from %s' % logfile)

        # Archive the sources
        if os.path.exists(local_sources):
            logger.info('Creating tarballs in %s...' % local_sources)
            if shutil.which('pigz'):
                logger.info('Using pigz...')
                tar_opt = '-I pigz -cf'
            else:
                tar_opt = '-czf'
            for i in os.listdir(local_sources):
                cmd = 'tar --numeric-owner --remove-files %s %s.tar.gz %s' % (tar_opt, i, i)
                subprocess.check_call(cmd, shell=True, cwd=local_sources)

        if os.path.exists(self.pr_dir):
            shutil.copytree(self.pr_dir, os.path.join(local_handoff_dir, 'prserv'))

        # Create a symlink to latest dir
        os.symlink(date, os.path.join(self.local_upload_dir, 'latest'))

        logger.info('Done. Files are prepared in %s' % self.local_upload_dir)

        # Run rsync to remote url. Note, the slash '/' in cmd is very
        # important, otherwise, rsync would sync upload itself, but not the
        # files inside it.
        cmd = 'rsync -az %s/ %s' % (self.local_upload_dir, self.args.upload_url)
        logger.info('Running %s' % cmd)
        subprocess.check_call(cmd, shell=True)

    def gen_recipes(self):

        if os.getcwd() != self.builddir:
            raise Exception("This function must be run in BUILDDIR %s" % self.builddir)

        if self.machine:
            machines = [self.machine]
        else:
            machines = self.supported_machines

        new_lines = set()
        nonnul_src = set()

        bbclass_src = os.path.join(self.data_dir, 'wrlinux-print-pf.bbclass')
        bbclass_dst = os.path.join(self.local_layer, 'classes')

        logger.info('Copying wrlinux-print-pf.bbclass to %s' % bbclass_dst)
        logger.info('You can remove them manually if not needed any more')
        shutil.copy(bbclass_src, bbclass_dst)

        preconf = os.path.join(self.data_dir, 'wrlinux-print-pf.conf')

        def write_set_to_file(set_data, outfile):
            set_data_list = list(pf_set)
            set_data_list.sort()

            logger.info('Saving recipes to %s' % outfile)
            with open(outfile, 'w') as f:
                for pf in set_data_list:
                    f.write('%s\n' % pf)

        for machine in machines:
            logger.info('Generating recipes list for %s' % machine)
            # Clean bb_cache.dat to make it reparse and print pf for recipes which have source
            cache_dir = os.path.join('tmp-%s-glibc' % machine, 'cache/default-glibc')
            if os.path.exists(cache_dir):
                shutil.rmtree(cache_dir)

            logfile = os.path.join('tmp-%s-glibc/log' % machine, 'cooker', machine, 'console-latest.log')

            # The docker won't be built in a world build since it is started with "virtual/".
            self.do_build('-r %s -g world docker %s' % (preconf, ' '.join(self.images)), conf='MACHINE="%s"\n' % machine)

            with open(logfile, 'r') as f:
                nonnul_src |= set(f.readlines())

            world_list = 'task-depends-world-%s.dot' % machine
            os.rename('task-depends.dot', world_list)

            # And sdk
            sdk_list = 'task-depends-sdk-%s.dot' % machine
            self.do_build('%s -g -cpopulate_sdk' % self.image)
            os.rename('task-depends.dot', sdk_list)

            for dot in (world_list, sdk_list):
                with open(dot, 'r') as f:
                    for line in f.readlines():
                        if '[label=' in line:
                            new_lines.add(line)

        pf_set = set()
        for line in new_lines:
            pn = line.split('.do_')[0].strip('"')
            if pn.endswith('-native'):
                continue
            pv = line.split('\\n')[1]
            # Handle pe
            if pv.startswith(':'):
                pv = pv[1:]
            else:
                pe = pv.split(':')[0] + '_'
                pv = pe + pv.split(':')[1]
            pf = '%s-%s' % (pn, pv)
            pf_set.add(pf)

        write_set_to_file(pf_set, 'recipes-list')

        print_pf_key = ' PRINT_PF: '
        print_pf_new = set()
        for line in nonnul_src:
            if print_pf_key in line:
                print_pf_new.add(line.split(print_pf_key)[1].strip())

        pf_set &= print_pf_new
        set_data_list = list(pf_set)
        set_data_list.sort()

        write_set_to_file(pf_set, 'recipes-list-src')

    def is_ci_branch(self):
        try:
            g = git.cmd.Git(self.data_dir)
            head_name = g.rev_parse('--symbolic-full-name', 'm/master')
            if head_name.endswith('/WRLINUX_CI'):
                return True
        except Exception as e:
            logger.error('Failed to check ci branch: %s' % e)

        return False

def main():
    gen = GenImage()

    if gen.args.upload_url:
        gen.do_upload()
    else:
        gen.prepare()
        if gen.args.ip_review:
            gen.ip_review()
        elif gen.args.gen_recipes:
            gen.gen_recipes()
        else:
            gen.gen_ostree()
            gen.gen_container()
            gen.gen_sdk()
            gen.gen_lat()
            gen.gen_feeds()
            # Gen ip sources for WRLINUX_CI branch
            if gen.is_ci_branch():
                gen.ip_review()

            gen.post()

if __name__ == "__main__":
    try:
        ret = main()
    except Exception as esc:
        ret = 1
        import traceback
        traceback.print_exc()
    sys.exit(ret)
